{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import spacy\n",
    "from torch import nn\n",
    "\n",
    "from torch import optim\n",
    "from torch.optim import Adam\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, d_model, eps=1e-12):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(d_model))\n",
    "        self.beta = nn.Parameter(torch.zeros(d_model))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        var = x.var(-1, unbiased=False, keepdim=True)\n",
    "        # '-1' means last dimension. \n",
    "        out = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        out = self.gamma * out + self.beta\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleDotProductAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScaleDotProductAttention,self).__init__()\n",
    "        self.softmax=nn.Softmax(dim=-1)\n",
    "    \n",
    "    def forward(self,q,k,v,mask=None,e=1e-12):\n",
    "        batch_size,head,length,d_tensor=k.size()\n",
    "        k_t=k.transpose(2,3)\n",
    "        score=(q@k_t)/math.sqrt(d_tensor)\n",
    "        \n",
    "        if mask is not None:\n",
    "            score=score.masked_fill(mask==0,-10000)\n",
    "            \n",
    "        score=self.softmax(score)\n",
    "        v=score@v\n",
    "        \n",
    "        return v,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self,d_model,hidden,drop_prob=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, hidden)\n",
    "        self.linear2 = nn.Linear(hidden, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=drop_prob)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self,n_head,d_model):\n",
    "        super(MultiHeadAttention,self).__init__()\n",
    "        self.n_head=n_head\n",
    "        self.attention=ScaleDotProductAttention()\n",
    "        self.w_q=nn.Linear(d_model,d_model)\n",
    "        self.w_k=nn.Linear(d_model,d_model)\n",
    "        self.w_v=nn.Linear(d_model,d_model)\n",
    "        self.w_concat=nn.Linear(d_model,d_model) #linear after concat\n",
    "    \n",
    "    def split(self,tensor):\n",
    "        batch_size,length,d_model=tensor.size()\n",
    "        d_tensor=d_model//self.n_head\n",
    "        tensor=tensor.view(batch_size,length,self.n_head,d_tensor).transpose(1,2)\n",
    "        return tensor\n",
    "    \n",
    "    def concat(self, tensor):\n",
    "        batch_size,head,length,d_tensor=tensor.size()\n",
    "        d_model=head*d_tensor\n",
    "        tensor = tensor.transpose(1, 2).contiguous().view(batch_size, length, d_model)\n",
    "        return tensor\n",
    "            \n",
    "    def forward(self,q,k,v,mask=None):\n",
    "        q,k,v=self.w_q(q),self.w_k(k),self.w_v(v)\n",
    "        q,k,v=self.split(q),self.split(k),self.split(v)\n",
    "        out, attention = self.attention(q, k, v, mask=mask)\n",
    "        \n",
    "        out = self.concat(out)\n",
    "        out = self.w_concat(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, max_len,device):\n",
    "        super(PositionalEncoding,self).__init__()\n",
    "\n",
    "        self.encoding=torch.zeros((max_len,d_model), device=device)\n",
    "        self.encoding.requires_grad=False\n",
    "\n",
    "        pos=torch.arange(0,max_len,device=device)\n",
    "        pos=pos.float().unsqueeze(dim=1)\n",
    "        \n",
    "        _2i=torch.arange(0,d_model,step=2,device=device).float()\n",
    "        self.encoding[:,0::2]=torch.sin(pos/(10000**(_2i/d_model)))\n",
    "        self.encoding[:,1::2]=torch.cos(pos/(10000**(_2i/d_model)))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        batch_size,seq_len=x.size()\n",
    "        return self.encoding[:seq_len,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding(nn.Embedding):\n",
    "    \n",
    "    def __init__(self, vocab_size,d_model):\n",
    "        super().__init__(vocab_size,d_model,padding_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEmbedding(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size,d_model,max_len,drop_prob,device):\n",
    "        super().__init__()\n",
    "        self.tok_emb=TokenEmbedding(vocab_size,d_model)\n",
    "        self.pos_emb=PositionalEncoding(d_model,max_len,device)\n",
    "        self.drop_out=nn.Dropout(p=drop_prob)\n",
    "        \n",
    "    def  forward(self,x):\n",
    "        tok_emb=self.tok_emb(x)\n",
    "        pos_emb=self.pos_emb(x)\n",
    "        return self.drop_out(tok_emb+pos_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model,ffn_hidden,n_head,drop_prob):\n",
    "        super().__init__()\n",
    "        self.attention=MultiHeadAttention(d_model=d_model,n_head=n_head)\n",
    "        self.norm1=LayerNorm(d_model=d_model)\n",
    "        self.dropout1=nn.Dropout(p=drop_prob)\n",
    "        \n",
    "        self.ffn=PositionwiseFeedForward(d_model=d_model,hidden=ffn_hidden,drop_prob=drop_prob)\n",
    "        self.norm2=LayerNorm(d_model=d_model)\n",
    "        self.dropout2=nn.Dropout(p=drop_prob)\n",
    "        \n",
    "        \n",
    "    def forward(self,x,src_mask):\n",
    "        _x=x\n",
    "        x=self.attention(q=x,k=x,v=x,mask=src_mask)\n",
    "        x=self.dropout1(x)\n",
    "        x=self.norm1(x+_x)\n",
    "        \n",
    "        _x=x\n",
    "        x=self.ffn(x)\n",
    "        x=self.dropout2(x)\n",
    "        x=self.norm2(x+_x)\n",
    "        return x\n",
    "         \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self,d_model,ffn_hidden,n_head,drop_prob):\n",
    "        super().__init__()\n",
    "        self.attention=MultiHeadAttention(d_model=d_model,n_head=n_head)\n",
    "        self.dropout1=nn.Dropout(p=drop_prob)\n",
    "        self.norm1=LayerNorm(d_model=d_model)\n",
    "        \n",
    "        self.dec_enc_attention=MultiHeadAttention(d_model=d_model,n_head=n_head)\n",
    "        self.dropout2=nn.Dropout(p=drop_prob)\n",
    "        self.norm2=LayerNorm(d_model=d_model)\n",
    "        \n",
    "        self.ffn=PositionwiseFeedForward(d_model=d_model,hidden=ffn_hidden,drop_prob=drop_prob)\n",
    "        self.dropout3=nn.Dropout(p=drop_prob)\n",
    "        self.norm3=LayerNorm(d_model=d_model)\n",
    "    \n",
    "    def forward(self,dec,enc,trg_mask,src_mask):\n",
    "        _x=dec\n",
    "        x=self.attention(q=dec,k=dec,v=dec,mask=trg_mask)\n",
    "        x=self.dropout1(x)\n",
    "        x=self.norm1(x+_x)\n",
    "        \n",
    "        if enc is not None:\n",
    "            _x=x\n",
    "            x=self.dec_enc_attention(q=x,k=enc,v=enc,mask=src_mask)\n",
    "            x=self.dropout2(x)\n",
    "            x=self.norm2(x+_x)\n",
    "            \n",
    "        _x=x\n",
    "        x=self.ffn(x)\n",
    "        x=self.dropout3(x)\n",
    "        x=self.norm3(x+_x)\n",
    "        return x\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, enc_voc_size,max_len,d_model,ffn_hidden,n_head,n_layers,drop_prob,device):\n",
    "        super().__init__()\n",
    "        self.emb=TransformerEmbedding(vocab_size=enc_voc_size,d_model=d_model,max_len=max_len,drop_prob=drop_prob,device=device)\n",
    "        self.layers=nn.ModuleList([EncoderLayer(d_model=d_model,ffn_hidden=ffn_hidden,n_head=n_head,drop_prob=drop_prob) for _ in range(0, n_layers)])\n",
    "    \n",
    "    def forward(self,x,src_mask):\n",
    "        x=self.emb(x)\n",
    "        for layer in self.layers:\n",
    "            x=layer(x,src_mask)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, dec_voc_size, max_len, d_model, ffn_hidden, n_head, n_layers, drop_prob, device):\n",
    "        super().__init__()\n",
    "        self.emb = TransformerEmbedding(d_model=d_model, drop_prob=drop_prob,max_len=max_len, vocab_size=dec_voc_size, device=device)\n",
    "\n",
    "        self.layers = nn.ModuleList([DecoderLayer(d_model=d_model, ffn_hidden=ffn_hidden, n_head=n_head,drop_prob=drop_prob) for _ in range(n_layers)])\n",
    "        \n",
    "        self.linear=nn.Linear(d_model,dec_voc_size)\n",
    "        \n",
    "    def forward(self,trg,enc_src,trg_mask,src_mask):\n",
    "        trg=self.emb(trg)\n",
    "        for layer in self.layers:\n",
    "            trg=layer(trg,enc_src,trg_mask,src_mask)\n",
    "            \n",
    "        output=self.linear(trg)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self,src_pad_idx,trg_pad_idx,trg_sos_idx,enc_voc_size,dec_voc_size,d_model,n_head,max_len,ffn_hidden,n_layers,drop_prob,device):\n",
    "        super().__init__()\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.trg_sos_idx = trg_sos_idx\n",
    "        self.device = device\n",
    "        self.encoder = Encoder(d_model=d_model,\n",
    "                               n_head=n_head,\n",
    "                               max_len=max_len,\n",
    "                               ffn_hidden=ffn_hidden,\n",
    "                               enc_voc_size=enc_voc_size,\n",
    "                               drop_prob=drop_prob,\n",
    "                               n_layers=n_layers,\n",
    "                               device=device)\n",
    "\n",
    "        self.decoder = Decoder(d_model=d_model,\n",
    "                               n_head=n_head,\n",
    "                               max_len=max_len,\n",
    "                               ffn_hidden=ffn_hidden,\n",
    "                               dec_voc_size=dec_voc_size,\n",
    "                               drop_prob=drop_prob,\n",
    "                               n_layers=n_layers,\n",
    "                               device=device)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        enc_src = self.encoder(src, src_mask)\n",
    "        output = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
    "        return output\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        return src_mask\n",
    "\n",
    "    def make_trg_mask(self, trg):\n",
    "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(3)\n",
    "        trg_len = trg.shape[1]\n",
    "        trg_sub_mask = torch.tril(torch.ones(trg_len, trg_len)).type(torch.ByteTensor).to(self.device)\n",
    "        trg_mask = trg_pad_mask & trg_sub_mask\n",
    "        return trg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:cuda:0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "max_len = 256\n",
    "d_model = 512\n",
    "n_layers = 6\n",
    "n_heads = 8\n",
    "ffn_hidden = 2048\n",
    "drop_prob = 0.1\n",
    "\n",
    "init_lr = 1e-5\n",
    "factor = 0.9\n",
    "adam_eps = 5e-9\n",
    "patience = 10\n",
    "warmup = 100\n",
    "epoch = 1000\n",
    "clip = 1.0\n",
    "weight_decay = 5e-4\n",
    "inf = float('inf')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device:{device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "tokenizer_de = get_tokenizer('spacy', language='de_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = Multi30k(root=\".data\", split='train', language_pair=('de', 'en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter, tokenizer, language):\n",
    "    for data_sample in data_iter:\n",
    "        yield tokenizer(data_sample[language])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test01/anaconda3/envs/last/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/combining.py:337: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    }
   ],
   "source": [
    "# 构建词汇表\n",
    "vocab_de = build_vocab_from_iterator(\n",
    "    yield_tokens(train_iter, tokenizer_de, language=0),\n",
    "    specials=['<unk>', '<pad>', '<bos>', '<eos>'],\n",
    "    min_freq=2\n",
    ")\n",
    "vocab_en = build_vocab_from_iterator(\n",
    "    yield_tokens(train_iter, tokenizer_en, language=1),\n",
    "    specials=['<unk>', '<pad>', '<bos>', '<eos>'],\n",
    "    min_freq=2\n",
    ")\n",
    "\n",
    "# 设置默认未知词标记\n",
    "vocab_de.set_default_index(vocab_de['<unk>'])\n",
    "vocab_en.set_default_index(vocab_en['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_pad_idx = 1\n",
    "trg_pad_idx = 1\n",
    "trg_sos_idx = 2\n",
    "enc_voc_size = len(vocab_en)\n",
    "dec_voc_size = len(vocab_de)\n",
    "model = Transformer(src_pad_idx=src_pad_idx,trg_pad_idx=trg_pad_idx,trg_sos_idx=trg_sos_idx,\n",
    "                    d_model=d_model,enc_voc_size=enc_voc_size, \n",
    "                    dec_voc_size=dec_voc_size,max_len=max_len,ffn_hidden=ffn_hidden,n_head=n_heads,\n",
    "                    n_layers=n_layers, drop_prob=drop_prob,device=device).to(device)\n",
    "\n",
    "# come here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=src_pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    \n",
    "    de_batch, en_batch = [], []\n",
    "    for de, en in batch:\n",
    "        # 德语端添加 <bos> 和 <eos>\n",
    "        de_processed = [vocab_de['<bos>']] + vocab_de(tokenizer_de(de)) + [vocab_de['<eos>']]\n",
    "        # 英语端同理\n",
    "        en_processed = [vocab_en['<bos>']] + vocab_en(tokenizer_en(en)) + [vocab_en['<eos>']]\n",
    "        \n",
    "        de_batch.append(torch.tensor(de_processed, dtype=torch.long))\n",
    "        en_batch.append(torch.tensor(en_processed, dtype=torch.long))\n",
    "    \n",
    "    # 填充到相同长度\n",
    "    de_padded = pad_sequence(de_batch, padding_value=vocab_de['<pad>'], batch_first=True)\n",
    "    en_padded = pad_sequence(en_batch, padding_value=vocab_en['<pad>'], batch_first=True)\n",
    "\n",
    "    return de_padded, en_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "# 重新加载数据集（因为迭代器只能遍历一次）\n",
    "train_iter = Multi30k(split='train', language_pair=('de', 'en'))\n",
    "valid_iter = Multi30k(split='valid', language_pair=('de', 'en'))\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    list(train_iter),  # 转换为列表（Multi30k 是迭代器）\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    list(valid_iter),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 37])\n",
      "英语张量形状: torch.Size([128, 40])\n",
      "torch.Size([128, 36])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 36])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 35])\n",
      "德语张量形状: torch.Size([128, 38])\n",
      "英语张量形状: torch.Size([128, 37])\n",
      "torch.Size([128, 37])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 37])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 36])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 35])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 38])\n",
      "英语张量形状: torch.Size([128, 37])\n",
      "torch.Size([128, 37])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 32])\n",
      "英语张量形状: torch.Size([128, 25])\n",
      "torch.Size([128, 31])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 36])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 32])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 31])\n",
      "德语张量形状: torch.Size([128, 38])\n",
      "英语张量形状: torch.Size([128, 37])\n",
      "torch.Size([128, 37])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 33])\n",
      "英语张量形状: torch.Size([128, 35])\n",
      "torch.Size([128, 32])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 33])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 25])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 25])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 36])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 35])\n",
      "德语张量形状: torch.Size([128, 32])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 31])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 32])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 31])\n",
      "德语张量形状: torch.Size([128, 33])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 32])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 33])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 32])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 32])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 31])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 34])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 38])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 38])\n",
      "英语张量形状: torch.Size([128, 36])\n",
      "torch.Size([128, 37])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 33])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 32])\n",
      "英语张量形状: torch.Size([128, 35])\n",
      "torch.Size([128, 31])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 32])\n",
      "英语张量形状: torch.Size([128, 33])\n",
      "torch.Size([128, 31])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 34])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 32])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 31])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 33])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 34])\n",
      "英语张量形状: torch.Size([128, 33])\n",
      "torch.Size([128, 33])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 25])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 32])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 31])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 34])\n",
      "英语张量形状: torch.Size([128, 35])\n",
      "torch.Size([128, 33])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 33])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 32])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 33])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 32])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 31])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 37])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 36])\n",
      "英语张量形状: torch.Size([128, 43])\n",
      "torch.Size([128, 35])\n",
      "德语张量形状: torch.Size([128, 33])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 32])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 36])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 34])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 37])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 36])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 46])\n",
      "英语张量形状: torch.Size([128, 37])\n",
      "torch.Size([128, 45])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 24])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 33])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 25])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 24])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 24])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 37])\n",
      "英语张量形状: torch.Size([128, 36])\n",
      "torch.Size([128, 36])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 24])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 23])\n",
      "英语张量形状: torch.Size([128, 24])\n",
      "torch.Size([128, 22])\n",
      "德语张量形状: torch.Size([128, 35])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 34])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 34])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 34])\n",
      "英语张量形状: torch.Size([128, 37])\n",
      "torch.Size([128, 33])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 34])\n",
      "英语张量形状: torch.Size([128, 34])\n",
      "torch.Size([128, 33])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 24])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 23])\n",
      "德语张量形状: torch.Size([128, 37])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 36])\n",
      "德语张量形状: torch.Size([128, 34])\n",
      "英语张量形状: torch.Size([128, 33])\n",
      "torch.Size([128, 33])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 36])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 25])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 45])\n",
      "英语张量形状: torch.Size([128, 42])\n",
      "torch.Size([128, 44])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 33])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 32])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 25])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 24])\n",
      "德语张量形状: torch.Size([128, 35])\n",
      "英语张量形状: torch.Size([128, 35])\n",
      "torch.Size([128, 34])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 32])\n",
      "英语张量形状: torch.Size([128, 34])\n",
      "torch.Size([128, 31])\n",
      "德语张量形状: torch.Size([128, 25])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 24])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 33])\n",
      "英语张量形状: torch.Size([128, 35])\n",
      "torch.Size([128, 32])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 25])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 36])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 35])\n",
      "德语张量形状: torch.Size([128, 25])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 24])\n",
      "德语张量形状: torch.Size([128, 36])\n",
      "英语张量形状: torch.Size([128, 38])\n",
      "torch.Size([128, 35])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 24])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 23])\n",
      "德语张量形状: torch.Size([128, 36])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 35])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 34])\n",
      "英语张量形状: torch.Size([128, 41])\n",
      "torch.Size([128, 33])\n",
      "德语张量形状: torch.Size([128, 32])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 31])\n",
      "德语张量形状: torch.Size([128, 33])\n",
      "英语张量形状: torch.Size([128, 38])\n",
      "torch.Size([128, 32])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 25])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 33])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 25])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 24])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 25])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 24])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 34])\n",
      "英语张量形状: torch.Size([128, 40])\n",
      "torch.Size([128, 33])\n",
      "德语张量形状: torch.Size([128, 25])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 24])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 37])\n",
      "英语张量形状: torch.Size([128, 40])\n",
      "torch.Size([128, 36])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 33])\n",
      "英语张量形状: torch.Size([128, 35])\n",
      "torch.Size([128, 32])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 35])\n",
      "英语张量形状: torch.Size([128, 33])\n",
      "torch.Size([128, 34])\n",
      "德语张量形状: torch.Size([128, 33])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 32])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 35])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 33])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 32])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 32])\n",
      "英语张量形状: torch.Size([128, 34])\n",
      "torch.Size([128, 31])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 37])\n",
      "英语张量形状: torch.Size([128, 36])\n",
      "torch.Size([128, 36])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 33])\n",
      "英语张量形状: torch.Size([128, 33])\n",
      "torch.Size([128, 32])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 25])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 32])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 31])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 25])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 24])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 25])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 24])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 38])\n",
      "英语张量形状: torch.Size([128, 37])\n",
      "torch.Size([128, 37])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 34])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 33])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 23])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 22])\n",
      "德语张量形状: torch.Size([128, 38])\n",
      "英语张量形状: torch.Size([128, 36])\n",
      "torch.Size([128, 37])\n",
      "德语张量形状: torch.Size([128, 33])\n",
      "英语张量形状: torch.Size([128, 34])\n",
      "torch.Size([128, 32])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 32])\n",
      "英语张量形状: torch.Size([128, 34])\n",
      "torch.Size([128, 31])\n",
      "德语张量形状: torch.Size([128, 25])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 24])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 33])\n",
      "英语张量形状: torch.Size([128, 34])\n",
      "torch.Size([128, 32])\n",
      "德语张量形状: torch.Size([128, 35])\n",
      "英语张量形状: torch.Size([128, 40])\n",
      "torch.Size([128, 34])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 24])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 23])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 34])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 33])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 45])\n",
      "英语张量形状: torch.Size([128, 41])\n",
      "torch.Size([128, 44])\n",
      "德语张量形状: torch.Size([128, 24])\n",
      "英语张量形状: torch.Size([128, 24])\n",
      "torch.Size([128, 23])\n",
      "德语张量形状: torch.Size([128, 41])\n",
      "英语张量形状: torch.Size([128, 42])\n",
      "torch.Size([128, 40])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([73, 25])\n",
      "英语张量形状: torch.Size([73, 25])\n",
      "torch.Size([73, 24])\n",
      "9.134526513221505\n"
     ]
    }
   ],
   "source": [
    "losssum=0\n",
    "for de, en in train_loader:\n",
    "    print(f\"德语张量形状: {de.shape}\")  # (seq_len, batch_size)\n",
    "    print(f\"英语张量形状: {en.shape}\")\n",
    "    trg=de.to(device)\n",
    "    src=en.to(device)\n",
    "    print(trg[:, :-1].shape)\n",
    "    output = model(src, trg[:, :-1])\n",
    "    #print(output)\n",
    "    loss = criterion(\n",
    "                output.reshape(-1, output.shape[2]),\n",
    "                trg[:, 1:].reshape(-1)\n",
    "            )\n",
    "    #print(loss)\n",
    "    #loss.backward()\n",
    "    losssum = losssum+loss.item()\n",
    "print(losssum/len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 13])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = \"Two young, White males are outside near many bushes.\"\n",
    "trg = \"Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.\"\n",
    "src_list =tokenizer_en(src)\n",
    "src_ids = [vocab_en[i] for i in src_list]\n",
    "\n",
    "src_ids = torch.tensor(src_ids, device=device).unsqueeze(0)\n",
    "\n",
    "\n",
    "trg_list =tokenizer_de(trg)\n",
    "trg_ids = [vocab_de[i] for i in trg_list]\n",
    "\n",
    "trg_ids = torch.tensor(trg_ids, device=device).unsqueeze(0)\n",
    "trg_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=model(src_ids,trg_ids[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6547, -0.8189, -1.1100,  ..., -0.0604,  0.2793, -0.0587],\n",
       "         [ 1.2272, -0.8595, -1.1362,  ..., -0.1330,  0.0925,  0.5861],\n",
       "         [ 1.4104, -0.6988, -0.2785,  ..., -0.2961,  0.8724,  0.4392],\n",
       "         ...,\n",
       "         [ 0.6621, -1.0726, -0.4906,  ..., -0.1625,  0.6817, -0.5143],\n",
       "         [ 0.4890,  0.0432,  0.1038,  ..., -0.1351,  0.7973, -0.5806],\n",
       "         [ 0.3995,  0.1899, -1.0841,  ..., -0.1204,  0.5818,  0.6081]]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 8014])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_reshape = output.contiguous().view(-1, output.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 8014])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_ids = trg_ids[:, 1:].contiguous().view(-1)\n",
    "trg_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.1797, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "loss = criterion(output_reshape, trg_ids)\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.transforms import VocabTransform, Sequential, ToTensor, AddToken\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, ext, tokenize_en, tokenize_de, init_token, eos_token):\n",
    "        self.ext = ext\n",
    "        self.tokenize_en = tokenize_en\n",
    "        self.tokenize_de = tokenize_de\n",
    "        self.init_token = init_token\n",
    "        self.eos_token = eos_token\n",
    "        self.source_vocab = None\n",
    "        self.target_vocab = None\n",
    "        print('dataset initializing start')\n",
    "\n",
    "    def make_dataset(self):\n",
    "        # Load Multi30k dataset (new API)\n",
    "        train_data, valid_data, test_data = Multi30k(split=('train', 'valid', 'test'), language_pair=self.ext)\n",
    "        return train_data, valid_data, test_data\n",
    "\n",
    "    def build_vocab(self, train_data, min_freq):\n",
    "        # Tokenize and build vocabulary for source and target languages\n",
    "        def yield_tokens(data_iter, tokenizer, index):\n",
    "            for data_pair in data_iter:\n",
    "                yield tokenizer(data_pair[index])\n",
    "\n",
    "        # Build source vocab (e.g., German)\n",
    "        src_tokenizer = self.tokenize_de if self.ext[0] == 'de' else self.tokenize_en\n",
    "        self.source_vocab = build_vocab_from_iterator(\n",
    "            yield_tokens(train_data, src_tokenizer, 0),\n",
    "            min_freq=min_freq,\n",
    "            specials=['<unk>', '<pad>', '<sos>', '<eos>']\n",
    "        )\n",
    "        self.source_vocab.set_default_index(self.source_vocab['<unk>'])\n",
    "\n",
    "        # Build target vocab (e.g., English)\n",
    "        tgt_tokenizer = self.tokenize_en if self.ext[1] == 'en' else self.tokenize_de\n",
    "        self.target_vocab = build_vocab_from_iterator(\n",
    "            yield_tokens(train_data, tgt_tokenizer, 1),\n",
    "            min_freq=min_freq,\n",
    "            specials=['<unk>', '<pad>', '<sos>', '<eos>']\n",
    "        )\n",
    "        self.target_vocab.set_default_index(self.target_vocab['<unk>'])\n",
    "\n",
    "    def make_iter(self, train_data, valid_data, test_data, batch_size, device):\n",
    "        # Define transforms (tokenization + numericalization)\n",
    "        def apply_transform(vocab, tokenizer):\n",
    "            return Sequential(\n",
    "                tokenizer,  # Tokenize\n",
    "                AddToken(token=self.init_token, begin=True),  # Add <sos>\n",
    "                AddToken(token=self.eos_token, begin=False),  # Add <eos>\n",
    "                VocabTransform(vocab),  # Convert tokens to indices\n",
    "                ToTensor()  # Convert to tensor\n",
    "            )\n",
    "\n",
    "        # Source transform (e.g., German)\n",
    "        src_transform = apply_transform(\n",
    "            self.source_vocab,\n",
    "            self.tokenize_de if self.ext[0] == 'de' else self.tokenize_en\n",
    "        )\n",
    "\n",
    "        # Target transform (e.g., English)\n",
    "        tgt_transform = apply_transform(\n",
    "            self.target_vocab,\n",
    "            self.tokenize_en if self.ext[1] == 'en' else self.tokenize_de\n",
    "        )\n",
    "\n",
    "        # Collate function for DataLoader\n",
    "        def collate_fn(batch):\n",
    "            src_batch, tgt_batch = zip(*batch)\n",
    "            src_tensor = torch.stack([src_transform(text) for text in src_batch])\n",
    "            tgt_tensor = torch.stack([tgt_transform(text) for text in tgt_batch])\n",
    "            return src_tensor.to(device), tgt_tensor.to(device)\n",
    "\n",
    "        # Create DataLoader instances\n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "        valid_loader = DataLoader(valid_data, batch_size=batch_size, collate_fn=collate_fn)\n",
    "        test_loader = DataLoader(test_data, batch_size=batch_size, collate_fn=collate_fn)\n",
    "\n",
    "        print('dataset initializing done')\n",
    "        return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4648, -0.4333,  0.1012,  ..., -0.4403,  0.0777, -0.4330],\n",
       "         [ 0.2274, -0.8615,  0.3386,  ...,  0.0158,  0.4619, -0.5072],\n",
       "         [ 0.0226, -0.6698, -0.0226,  ..., -0.4404, -0.2434, -0.4011]],\n",
       "\n",
       "        [[-0.0404, -0.8512, -0.3359,  ...,  0.0251, -0.0610, -0.4031],\n",
       "         [ 0.2680, -0.8977, -0.4684,  ..., -0.1500,  0.1392, -0.2214],\n",
       "         [ 0.1542, -0.7848, -0.0398,  ..., -0.1032,  0.1595,  0.0902]],\n",
       "\n",
       "        [[ 0.0418, -0.9301,  0.0156,  ..., -0.1796,  0.2608, -0.6606],\n",
       "         [ 0.0209, -1.0345, -0.1234,  ..., -0.4663,  0.2392, -0.4593],\n",
       "         [ 0.4620, -0.9005,  0.1271,  ...,  0.1072,  0.0322, -0.3412]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.3228, -1.2411, -0.1310,  ...,  0.0359,  0.2161, -0.6517],\n",
       "         [ 0.3744, -0.7884, -0.1496,  ..., -0.2292,  0.2724, -0.7352],\n",
       "         [ 0.4333, -0.4514, -0.2970,  ..., -0.3743, -0.0146, -0.7926]],\n",
       "\n",
       "        [[-0.0907, -0.6279, -0.2216,  ..., -0.1000,  0.1889, -0.4347],\n",
       "         [-0.2049, -1.0031, -0.2154,  ..., -0.0159,  0.1634, -0.5213],\n",
       "         [-0.0445, -0.6938,  0.0574,  ...,  0.0554,  0.0879, -0.2041]],\n",
       "\n",
       "        [[ 0.1604, -0.6916, -0.4961,  ...,  0.0583,  0.3827, -0.7884],\n",
       "         [ 0.3089, -1.0491, -0.0388,  ..., -0.2814,  0.0523, -0.8692],\n",
       "         [ 0.2116, -0.8355, -0.0477,  ..., -0.3793,  0.6329, -0.6432]]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = torch.randint(0, 1, (10,3)).to(\"cuda:0\")\n",
    "trg = torch.randint(0, 1, (10,3)).to(\"cuda:0\")\n",
    "model(src,trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "last",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
