{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import spacy\n",
    "from torch import nn\n",
    "\n",
    "from torch import optim\n",
    "from torch.optim import Adam\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, d_model, eps=1e-12):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(d_model))\n",
    "        self.beta = nn.Parameter(torch.zeros(d_model))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        var = x.var(-1, unbiased=False, keepdim=True)\n",
    "        # '-1' means last dimension. \n",
    "        out = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        out = self.gamma * out + self.beta\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleDotProductAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScaleDotProductAttention,self).__init__()\n",
    "        self.softmax=nn.Softmax(dim=-1)\n",
    "    \n",
    "    def forward(self,q,k,v,mask=None,e=1e-12):\n",
    "        batch_size,head,length,d_tensor=k.size()\n",
    "        k_t=k.transpose(2,3)\n",
    "        score=(q@k_t)/math.sqrt(d_tensor)\n",
    "        \n",
    "        if mask is not None:\n",
    "            score=score.masked_fill(mask==0,-10000)\n",
    "            \n",
    "        score=self.softmax(score)\n",
    "        v=score@v\n",
    "        \n",
    "        return v,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self,d_model,hidden,drop_prob=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, hidden)\n",
    "        self.linear2 = nn.Linear(hidden, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=drop_prob)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self,n_head,d_model):\n",
    "        super(MultiHeadAttention,self).__init__()\n",
    "        self.n_head=n_head\n",
    "        self.attention=ScaleDotProductAttention()\n",
    "        self.w_q=nn.Linear(d_model,d_model)\n",
    "        self.w_k=nn.Linear(d_model,d_model)\n",
    "        self.w_v=nn.Linear(d_model,d_model)\n",
    "        self.w_concat=nn.Linear(d_model,d_model) #linear after concat\n",
    "    \n",
    "    def split(self,tensor):\n",
    "        batch_size,length,d_model=tensor.size()\n",
    "        d_tensor=d_model//self.n_head\n",
    "        tensor=tensor.view(batch_size,length,self.n_head,d_tensor).transpose(1,2)\n",
    "        return tensor\n",
    "    \n",
    "    def concat(self, tensor):\n",
    "        batch_size,head,length,d_tensor=tensor.size()\n",
    "        d_model=head*d_tensor\n",
    "        tensor = tensor.transpose(1, 2).contiguous().view(batch_size, length, d_model)\n",
    "        return tensor\n",
    "            \n",
    "    def forward(self,q,k,v,mask=None):\n",
    "        q,k,v=self.w_q(q),self.w_k(k),self.w_v(v)\n",
    "        q,k,v=self.split(q),self.split(k),self.split(v)\n",
    "        out, attention = self.attention(q, k, v, mask=mask)\n",
    "        \n",
    "        out = self.concat(out)\n",
    "        out = self.w_concat(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, max_len,device):\n",
    "        super(PositionalEncoding,self).__init__()\n",
    "\n",
    "        self.encoding=torch.zeros((max_len,d_model), device=device)\n",
    "        self.encoding.requires_grad=False\n",
    "\n",
    "        pos=torch.arange(0,max_len,device=device)\n",
    "        pos=pos.float().unsqueeze(dim=1)\n",
    "        \n",
    "        _2i=torch.arange(0,d_model,step=2,device=device).float()\n",
    "        self.encoding[:,0::2]=torch.sin(pos/(10000**(_2i/d_model)))\n",
    "        self.encoding[:,1::2]=torch.cos(pos/(10000**(_2i/d_model)))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        batch_size,seq_len=x.size()\n",
    "        return self.encoding[:seq_len,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding(nn.Embedding):\n",
    "    \n",
    "    def __init__(self, vocab_size,d_model):\n",
    "        super().__init__(vocab_size,d_model,padding_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEmbedding(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size,d_model,max_len,drop_prob,device):\n",
    "        super().__init__()\n",
    "        self.tok_emb=TokenEmbedding(vocab_size,d_model)\n",
    "        self.pos_emb=PositionalEncoding(d_model,max_len,device)\n",
    "        self.drop_out=nn.Dropout(p=drop_prob)\n",
    "        \n",
    "    def  forward(self,x):\n",
    "        tok_emb=self.tok_emb(x)\n",
    "        pos_emb=self.pos_emb(x)\n",
    "        return self.drop_out(tok_emb+pos_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model,ffn_hidden,n_head,drop_prob):\n",
    "        super().__init__()\n",
    "        self.attention=MultiHeadAttention(d_model=d_model,n_head=n_head)\n",
    "        self.norm1=LayerNorm(d_model=d_model)\n",
    "        self.dropout1=nn.Dropout(p=drop_prob)\n",
    "        \n",
    "        self.ffn=PositionwiseFeedForward(d_model=d_model,hidden=ffn_hidden,drop_prob=drop_prob)\n",
    "        self.norm2=LayerNorm(d_model=d_model)\n",
    "        self.dropout2=nn.Dropout(p=drop_prob)\n",
    "        \n",
    "        \n",
    "    def forward(self,x,src_mask):\n",
    "        _x=x\n",
    "        x=self.attention(q=x,k=x,v=x,mask=src_mask)\n",
    "        x=self.dropout1(x)\n",
    "        x=self.norm1(x+_x)\n",
    "        \n",
    "        _x=x\n",
    "        x=self.ffn(x)\n",
    "        x=self.dropout2(x)\n",
    "        x=self.norm2(x+_x)\n",
    "        return x\n",
    "         \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self,d_model,ffn_hidden,n_head,drop_prob):\n",
    "        super().__init__()\n",
    "        self.attention=MultiHeadAttention(d_model=d_model,n_head=n_head)\n",
    "        self.dropout1=nn.Dropout(p=drop_prob)\n",
    "        self.norm1=LayerNorm(d_model=d_model)\n",
    "        \n",
    "        self.dec_enc_attention=MultiHeadAttention(d_model=d_model,n_head=n_head)\n",
    "        self.dropout2=nn.Dropout(p=drop_prob)\n",
    "        self.norm2=LayerNorm(d_model=d_model)\n",
    "        \n",
    "        self.ffn=PositionwiseFeedForward(d_model=d_model,hidden=ffn_hidden,drop_prob=drop_prob)\n",
    "        self.dropout3=nn.Dropout(p=drop_prob)\n",
    "        self.norm3=LayerNorm(d_model=d_model)\n",
    "    \n",
    "    def forward(self,dec,enc,trg_mask,src_mask):\n",
    "        _x=dec\n",
    "        x=self.attention(q=dec,k=dec,v=dec,mask=trg_mask)\n",
    "        x=self.dropout1(x)\n",
    "        x=self.norm1(x+_x)\n",
    "        \n",
    "        if enc is not None:\n",
    "            _x=x\n",
    "            x=self.dec_enc_attention(q=x,k=enc,v=enc,mask=src_mask)\n",
    "            x=self.dropout2(x)\n",
    "            x=self.norm2(x+_x)\n",
    "            \n",
    "        _x=x\n",
    "        x=self.ffn(x)\n",
    "        x=self.dropout3(x)\n",
    "        x=self.norm3(x+_x)\n",
    "        return x\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, enc_voc_size,max_len,d_model,ffn_hidden,n_head,n_layers,drop_prob,device):\n",
    "        super().__init__()\n",
    "        self.emb=TransformerEmbedding(vocab_size=enc_voc_size,d_model=d_model,max_len=max_len,drop_prob=drop_prob,device=device)\n",
    "        self.layers=nn.ModuleList([EncoderLayer(d_model=d_model,ffn_hidden=ffn_hidden,n_head=n_head,drop_prob=drop_prob) for _ in range(0, n_layers)])\n",
    "    \n",
    "    def forward(self,x,src_mask):\n",
    "        x=self.emb(x)\n",
    "        for layer in self.layers:\n",
    "            x=layer(x,src_mask)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, dec_voc_size, max_len, d_model, ffn_hidden, n_head, n_layers, drop_prob, device):\n",
    "        super().__init__()\n",
    "        self.emb = TransformerEmbedding(d_model=d_model, drop_prob=drop_prob,max_len=max_len, vocab_size=dec_voc_size, device=device)\n",
    "\n",
    "        self.layers = nn.ModuleList([DecoderLayer(d_model=d_model, ffn_hidden=ffn_hidden, n_head=n_head,drop_prob=drop_prob) for _ in range(n_layers)])\n",
    "        \n",
    "        self.linear=nn.Linear(d_model,dec_voc_size)\n",
    "        \n",
    "    def forward(self,trg,enc_src,trg_mask,src_mask):\n",
    "        trg=self.emb(trg)\n",
    "        for layer in self.layers:\n",
    "            trg=layer(trg,enc_src,trg_mask,src_mask)\n",
    "            \n",
    "        output=self.linear(trg)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self,src_pad_idx,trg_pad_idx,trg_sos_idx,enc_voc_size,dec_voc_size,d_model,n_head,max_len,ffn_hidden,n_layers,drop_prob,device):\n",
    "        super().__init__()\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.trg_sos_idx = trg_sos_idx\n",
    "        self.device = device\n",
    "        self.encoder = Encoder(d_model=d_model,\n",
    "                               n_head=n_head,\n",
    "                               max_len=max_len,\n",
    "                               ffn_hidden=ffn_hidden,\n",
    "                               enc_voc_size=enc_voc_size,\n",
    "                               drop_prob=drop_prob,\n",
    "                               n_layers=n_layers,\n",
    "                               device=device)\n",
    "\n",
    "        self.decoder = Decoder(d_model=d_model,\n",
    "                               n_head=n_head,\n",
    "                               max_len=max_len,\n",
    "                               ffn_hidden=ffn_hidden,\n",
    "                               dec_voc_size=dec_voc_size,\n",
    "                               drop_prob=drop_prob,\n",
    "                               n_layers=n_layers,\n",
    "                               device=device)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        enc_src = self.encoder(src, src_mask)\n",
    "        output = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
    "        return output\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        return src_mask\n",
    "\n",
    "    def make_trg_mask(self, trg):\n",
    "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(3)\n",
    "        trg_len = trg.shape[1]\n",
    "        trg_sub_mask = torch.tril(torch.ones(trg_len, trg_len)).type(torch.ByteTensor).to(self.device)\n",
    "        trg_mask = trg_pad_mask & trg_sub_mask\n",
    "        return trg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:cuda:0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "max_len = 256\n",
    "d_model = 512\n",
    "n_layers = 6\n",
    "n_heads = 8\n",
    "ffn_hidden = 2048\n",
    "drop_prob = 0.1\n",
    "\n",
    "init_lr = 1e-5\n",
    "factor = 0.9\n",
    "adam_eps = 5e-9\n",
    "patience = 10\n",
    "warmup = 100\n",
    "epoch = 1000\n",
    "clip = 1.0\n",
    "weight_decay = 5e-4\n",
    "inf = float('inf')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device:{device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test01/anaconda3/envs/last/lib/python3.9/site-packages/torch/__init__.py:690: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "tokenizer_en = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "tokenizer_de = get_tokenizer('spacy', language='de_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = Multi30k(root=\".data\", split='train', language_pair=('de', 'en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter, tokenizer, language):\n",
    "    for data_sample in data_iter:\n",
    "        yield tokenizer(data_sample[language])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test01/anaconda3/envs/last/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/combining.py:337: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    }
   ],
   "source": [
    "# 构建词汇表\n",
    "vocab_de = build_vocab_from_iterator(\n",
    "    yield_tokens(train_iter, tokenizer_de, language=0),\n",
    "    specials=['<unk>', '<pad>', '<bos>', '<eos>'],\n",
    "    min_freq=2\n",
    ")\n",
    "vocab_en = build_vocab_from_iterator(\n",
    "    yield_tokens(train_iter, tokenizer_en, language=1),\n",
    "    specials=['<unk>', '<pad>', '<bos>', '<eos>'],\n",
    "    min_freq=2\n",
    ")\n",
    "\n",
    "# 设置默认未知词标记\n",
    "vocab_de.set_default_index(vocab_de['<unk>'])\n",
    "vocab_en.set_default_index(vocab_en['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_pad_idx = 1\n",
    "trg_pad_idx = 1\n",
    "trg_sos_idx = 2\n",
    "enc_voc_size = len(vocab_en)\n",
    "dec_voc_size = len(vocab_de)\n",
    "model = Transformer(src_pad_idx=src_pad_idx,trg_pad_idx=trg_pad_idx,trg_sos_idx=trg_sos_idx,\n",
    "                    d_model=d_model,enc_voc_size=enc_voc_size, \n",
    "                    dec_voc_size=dec_voc_size,max_len=max_len,ffn_hidden=ffn_hidden,n_head=n_heads,\n",
    "                    n_layers=n_layers, drop_prob=drop_prob,device=device).to(device)\n",
    "\n",
    "# come here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=src_pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    \n",
    "    de_batch, en_batch = [], []\n",
    "    for de, en in batch:\n",
    "        # 德语端添加 <bos> 和 <eos>\n",
    "        de_processed = [vocab_de['<bos>']] + vocab_de(tokenizer_de(de)) + [vocab_de['<eos>']]\n",
    "        # 英语端同理\n",
    "        en_processed = [vocab_en['<bos>']] + vocab_en(tokenizer_en(en)) + [vocab_en['<eos>']]\n",
    "        \n",
    "        de_batch.append(torch.tensor(de_processed, dtype=torch.long))\n",
    "        en_batch.append(torch.tensor(en_processed, dtype=torch.long))\n",
    "    \n",
    "    # 填充到相同长度\n",
    "    de_padded = pad_sequence(de_batch, padding_value=vocab_de['<pad>'], batch_first=True)\n",
    "    en_padded = pad_sequence(en_batch, padding_value=vocab_en['<pad>'], batch_first=True)\n",
    "\n",
    "    return de_padded, en_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "# 重新加载数据集（因为迭代器只能遍历一次）\n",
    "train_iter = Multi30k(split='train', language_pair=('de', 'en'))\n",
    "valid_iter = Multi30k(split='valid', language_pair=('de', 'en'))\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    list(train_iter),  # 转换为列表（Multi30k 是迭代器）\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    list(valid_iter),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 24])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 32])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 31])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 24])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 24])\n",
      "英语张量形状: torch.Size([128, 25])\n",
      "torch.Size([128, 23])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 36])\n",
      "英语张量形状: torch.Size([128, 38])\n",
      "torch.Size([128, 35])\n",
      "德语张量形状: torch.Size([128, 25])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 24])\n",
      "德语张量形状: torch.Size([128, 35])\n",
      "英语张量形状: torch.Size([128, 35])\n",
      "torch.Size([128, 34])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 34])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 36])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 35])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 32])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 31])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 36])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 24])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 23])\n",
      "德语张量形状: torch.Size([128, 25])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 24])\n",
      "德语张量形状: torch.Size([128, 38])\n",
      "英语张量形状: torch.Size([128, 37])\n",
      "torch.Size([128, 37])\n",
      "德语张量形状: torch.Size([128, 32])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 31])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 32])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 31])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 34])\n",
      "英语张量形状: torch.Size([128, 40])\n",
      "torch.Size([128, 33])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 32])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 31])\n",
      "德语张量形状: torch.Size([128, 36])\n",
      "英语张量形状: torch.Size([128, 38])\n",
      "torch.Size([128, 35])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 25])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 36])\n",
      "英语张量形状: torch.Size([128, 43])\n",
      "torch.Size([128, 35])\n",
      "德语张量形状: torch.Size([128, 35])\n",
      "英语张量形状: torch.Size([128, 35])\n",
      "torch.Size([128, 34])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 32])\n",
      "英语张量形状: torch.Size([128, 33])\n",
      "torch.Size([128, 31])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 34])\n",
      "英语张量形状: torch.Size([128, 41])\n",
      "torch.Size([128, 33])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 34])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 33])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 34])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 33])\n",
      "英语张量形状: torch.Size([128, 36])\n",
      "torch.Size([128, 32])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 32])\n",
      "英语张量形状: torch.Size([128, 37])\n",
      "torch.Size([128, 31])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 38])\n",
      "英语张量形状: torch.Size([128, 37])\n",
      "torch.Size([128, 37])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 33])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 24])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 23])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 34])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 37])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 36])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 25])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 24])\n",
      "德语张量形状: torch.Size([128, 33])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 32])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 36])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 35])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 32])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 31])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 25])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 46])\n",
      "英语张量形状: torch.Size([128, 37])\n",
      "torch.Size([128, 45])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 33])\n",
      "英语张量形状: torch.Size([128, 35])\n",
      "torch.Size([128, 32])\n",
      "德语张量形状: torch.Size([128, 25])\n",
      "英语张量形状: torch.Size([128, 25])\n",
      "torch.Size([128, 24])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 37])\n",
      "英语张量形状: torch.Size([128, 35])\n",
      "torch.Size([128, 36])\n",
      "德语张量形状: torch.Size([128, 34])\n",
      "英语张量形状: torch.Size([128, 34])\n",
      "torch.Size([128, 33])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 25])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 24])\n",
      "德语张量形状: torch.Size([128, 25])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 24])\n",
      "德语张量形状: torch.Size([128, 34])\n",
      "英语张量形状: torch.Size([128, 25])\n",
      "torch.Size([128, 33])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 37])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 33])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 32])\n",
      "德语张量形状: torch.Size([128, 38])\n",
      "英语张量形状: torch.Size([128, 37])\n",
      "torch.Size([128, 37])\n",
      "德语张量形状: torch.Size([128, 25])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 24])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 34])\n",
      "英语张量形状: torch.Size([128, 33])\n",
      "torch.Size([128, 33])\n",
      "德语张量形状: torch.Size([128, 33])\n",
      "英语张量形状: torch.Size([128, 34])\n",
      "torch.Size([128, 32])\n",
      "德语张量形状: torch.Size([128, 37])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 36])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 45])\n",
      "英语张量形状: torch.Size([128, 42])\n",
      "torch.Size([128, 44])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 32])\n",
      "英语张量形状: torch.Size([128, 35])\n",
      "torch.Size([128, 31])\n",
      "德语张量形状: torch.Size([128, 25])\n",
      "英语张量形状: torch.Size([128, 25])\n",
      "torch.Size([128, 24])\n",
      "德语张量形状: torch.Size([128, 38])\n",
      "英语张量形状: torch.Size([128, 39])\n",
      "torch.Size([128, 37])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 33])\n",
      "英语张量形状: torch.Size([128, 35])\n",
      "torch.Size([128, 32])\n",
      "德语张量形状: torch.Size([128, 33])\n",
      "英语张量形状: torch.Size([128, 35])\n",
      "torch.Size([128, 32])\n",
      "德语张量形状: torch.Size([128, 36])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 35])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 45])\n",
      "英语张量形状: torch.Size([128, 41])\n",
      "torch.Size([128, 44])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 25])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 24])\n",
      "德语张量形状: torch.Size([128, 23])\n",
      "英语张量形状: torch.Size([128, 25])\n",
      "torch.Size([128, 22])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 25])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 24])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 23])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 41])\n",
      "英语张量形状: torch.Size([128, 42])\n",
      "torch.Size([128, 40])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 37])\n",
      "英语张量形状: torch.Size([128, 40])\n",
      "torch.Size([128, 36])\n",
      "德语张量形状: torch.Size([128, 35])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 34])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 25])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 24])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 33])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 32])\n",
      "德语张量形状: torch.Size([128, 38])\n",
      "英语张量形状: torch.Size([128, 37])\n",
      "torch.Size([128, 37])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 25])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 36])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 35])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 25])\n",
      "英语张量形状: torch.Size([128, 24])\n",
      "torch.Size([128, 24])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 25])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 33])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 32])\n",
      "德语张量形状: torch.Size([128, 24])\n",
      "英语张量形状: torch.Size([128, 25])\n",
      "torch.Size([128, 23])\n",
      "德语张量形状: torch.Size([128, 34])\n",
      "英语张量形状: torch.Size([128, 37])\n",
      "torch.Size([128, 33])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 25])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 25])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 33])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 25])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 24])\n",
      "德语张量形状: torch.Size([128, 37])\n",
      "英语张量形状: torch.Size([128, 36])\n",
      "torch.Size([128, 36])\n",
      "德语张量形状: torch.Size([128, 25])\n",
      "英语张量形状: torch.Size([128, 25])\n",
      "torch.Size([128, 24])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 32])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 31])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 34])\n",
      "英语张量形状: torch.Size([128, 34])\n",
      "torch.Size([128, 33])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 24])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 23])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 32])\n",
      "英语张量形状: torch.Size([128, 34])\n",
      "torch.Size([128, 31])\n",
      "德语张量形状: torch.Size([128, 34])\n",
      "英语张量形状: torch.Size([128, 35])\n",
      "torch.Size([128, 33])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 34])\n",
      "英语张量形状: torch.Size([128, 33])\n",
      "torch.Size([128, 33])\n",
      "德语张量形状: torch.Size([128, 35])\n",
      "英语张量形状: torch.Size([128, 40])\n",
      "torch.Size([128, 34])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 33])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 31])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 30])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 36])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 33])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 32])\n",
      "德语张量形状: torch.Size([128, 35])\n",
      "英语张量形状: torch.Size([128, 37])\n",
      "torch.Size([128, 34])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 22])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 21])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 25])\n",
      "英语张量形状: torch.Size([128, 25])\n",
      "torch.Size([128, 24])\n",
      "德语张量形状: torch.Size([128, 32])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 31])\n",
      "德语张量形状: torch.Size([128, 26])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 25])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 33])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 32])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 31])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 38])\n",
      "英语张量形状: torch.Size([128, 36])\n",
      "torch.Size([128, 37])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 26])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 27])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 30])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 29])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 31])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 33])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 32])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 30])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([128, 37])\n",
      "英语张量形状: torch.Size([128, 38])\n",
      "torch.Size([128, 36])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 28])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 28])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 27])\n",
      "德语张量形状: torch.Size([128, 25])\n",
      "英语张量形状: torch.Size([128, 32])\n",
      "torch.Size([128, 24])\n",
      "德语张量形状: torch.Size([128, 27])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 26])\n",
      "德语张量形状: torch.Size([128, 29])\n",
      "英语张量形状: torch.Size([128, 29])\n",
      "torch.Size([128, 28])\n",
      "德语张量形状: torch.Size([73, 37])\n",
      "英语张量形状: torch.Size([73, 40])\n",
      "torch.Size([73, 36])\n",
      "9.154626854715893\n"
     ]
    }
   ],
   "source": [
    "losssum=0\n",
    "for de, en in train_loader:\n",
    "    print(f\"德语张量形状: {de.shape}\")  # (seq_len, batch_size)\n",
    "    print(f\"英语张量形状: {en.shape}\")\n",
    "    trg=de.to(device)\n",
    "    src=en.to(device)\n",
    "    print(trg[:, :-1].shape)\n",
    "    output = model(src, trg[:, :-1])\n",
    "    #print(output)\n",
    "    loss = criterion(\n",
    "                output.reshape(-1, output.shape[2]),\n",
    "                trg[:, 1:].reshape(-1)\n",
    "            )\n",
    "    #print(loss)\n",
    "    losssum = losssum+loss.item()\n",
    "print(losssum/len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 13])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = \"Two young, White males are outside near many bushes.\"\n",
    "trg = \"Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.\"\n",
    "src_list =tokenizer_en(src)\n",
    "src_ids = [vocab_en[i] for i in src_list]\n",
    "\n",
    "src_ids = torch.tensor(src_ids, device=device).unsqueeze(0)\n",
    "\n",
    "\n",
    "trg_list =tokenizer_de(trg)\n",
    "trg_ids = [vocab_de[i] for i in trg_list]\n",
    "\n",
    "trg_ids = torch.tensor(trg_ids, device=device).unsqueeze(0)\n",
    "trg_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=model(src_ids,trg_ids[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0028, -0.3290, -0.6634,  ..., -0.5386,  0.6408, -0.1188],\n",
       "         [-0.3230,  0.7530,  0.1407,  ..., -0.1449,  0.4592,  0.4360],\n",
       "         [-0.7534,  0.8151,  0.2188,  ...,  0.7032,  1.0184, -0.0790],\n",
       "         ...,\n",
       "         [-0.0218, -0.9069,  0.2163,  ...,  0.0677,  0.9946,  0.1321],\n",
       "         [-0.0149,  0.8431, -0.5896,  ..., -0.2367,  0.2445, -0.2734],\n",
       "         [-0.1857,  0.1189, -0.6281,  ...,  0.1665,  0.5034, -1.0686]]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_reshape = output.contiguous().view(-1, output.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 8014])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_ids = trg_ids[:, 1:].contiguous().view(-1)\n",
    "trg_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.9104, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "loss = criterion(output_reshape, trg_ids)\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.transforms import VocabTransform, Sequential, ToTensor, AddToken\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, ext, tokenize_en, tokenize_de, init_token, eos_token):\n",
    "        self.ext = ext\n",
    "        self.tokenize_en = tokenize_en\n",
    "        self.tokenize_de = tokenize_de\n",
    "        self.init_token = init_token\n",
    "        self.eos_token = eos_token\n",
    "        self.source_vocab = None\n",
    "        self.target_vocab = None\n",
    "        print('dataset initializing start')\n",
    "\n",
    "    def make_dataset(self):\n",
    "        # Load Multi30k dataset (new API)\n",
    "        train_data, valid_data, test_data = Multi30k(split=('train', 'valid', 'test'), language_pair=self.ext)\n",
    "        return train_data, valid_data, test_data\n",
    "\n",
    "    def build_vocab(self, train_data, min_freq):\n",
    "        # Tokenize and build vocabulary for source and target languages\n",
    "        def yield_tokens(data_iter, tokenizer, index):\n",
    "            for data_pair in data_iter:\n",
    "                yield tokenizer(data_pair[index])\n",
    "\n",
    "        # Build source vocab (e.g., German)\n",
    "        src_tokenizer = self.tokenize_de if self.ext[0] == 'de' else self.tokenize_en\n",
    "        self.source_vocab = build_vocab_from_iterator(\n",
    "            yield_tokens(train_data, src_tokenizer, 0),\n",
    "            min_freq=min_freq,\n",
    "            specials=['<unk>', '<pad>', '<sos>', '<eos>']\n",
    "        )\n",
    "        self.source_vocab.set_default_index(self.source_vocab['<unk>'])\n",
    "\n",
    "        # Build target vocab (e.g., English)\n",
    "        tgt_tokenizer = self.tokenize_en if self.ext[1] == 'en' else self.tokenize_de\n",
    "        self.target_vocab = build_vocab_from_iterator(\n",
    "            yield_tokens(train_data, tgt_tokenizer, 1),\n",
    "            min_freq=min_freq,\n",
    "            specials=['<unk>', '<pad>', '<sos>', '<eos>']\n",
    "        )\n",
    "        self.target_vocab.set_default_index(self.target_vocab['<unk>'])\n",
    "\n",
    "    def make_iter(self, train_data, valid_data, test_data, batch_size, device):\n",
    "        # Define transforms (tokenization + numericalization)\n",
    "        def apply_transform(vocab, tokenizer):\n",
    "            return Sequential(\n",
    "                tokenizer,  # Tokenize\n",
    "                AddToken(token=self.init_token, begin=True),  # Add <sos>\n",
    "                AddToken(token=self.eos_token, begin=False),  # Add <eos>\n",
    "                VocabTransform(vocab),  # Convert tokens to indices\n",
    "                ToTensor()  # Convert to tensor\n",
    "            )\n",
    "\n",
    "        # Source transform (e.g., German)\n",
    "        src_transform = apply_transform(\n",
    "            self.source_vocab,\n",
    "            self.tokenize_de if self.ext[0] == 'de' else self.tokenize_en\n",
    "        )\n",
    "\n",
    "        # Target transform (e.g., English)\n",
    "        tgt_transform = apply_transform(\n",
    "            self.target_vocab,\n",
    "            self.tokenize_en if self.ext[1] == 'en' else self.tokenize_de\n",
    "        )\n",
    "\n",
    "        # Collate function for DataLoader\n",
    "        def collate_fn(batch):\n",
    "            src_batch, tgt_batch = zip(*batch)\n",
    "            src_tensor = torch.stack([src_transform(text) for text in src_batch])\n",
    "            tgt_tensor = torch.stack([tgt_transform(text) for text in tgt_batch])\n",
    "            return src_tensor.to(device), tgt_tensor.to(device)\n",
    "\n",
    "        # Create DataLoader instances\n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "        valid_loader = DataLoader(valid_data, batch_size=batch_size, collate_fn=collate_fn)\n",
    "        test_loader = DataLoader(test_data, batch_size=batch_size, collate_fn=collate_fn)\n",
    "\n",
    "        print('dataset initializing done')\n",
    "        return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0453e+00, -1.1709e-01, -1.6439e-01,  ...,  1.0379e+00,\n",
       "          -9.8775e-02,  5.0622e-01],\n",
       "         [-9.2150e-01, -3.3230e-01, -3.8646e-01,  ...,  7.3773e-01,\n",
       "          -3.2671e-01,  6.5908e-01],\n",
       "         [-1.0421e+00, -7.7217e-02, -3.3679e-01,  ...,  9.3421e-01,\n",
       "          -2.3224e-01,  3.3822e-01]],\n",
       "\n",
       "        [[-1.0624e+00,  1.1289e-01, -5.4295e-01,  ...,  7.3971e-01,\n",
       "          -8.1724e-01,  9.7228e-02],\n",
       "         [-6.6536e-01, -2.0220e-01, -3.4827e-01,  ...,  7.0489e-01,\n",
       "           3.0030e-01,  4.9444e-01],\n",
       "         [-7.0036e-01,  4.1444e-02, -1.9336e-01,  ...,  7.2447e-01,\n",
       "          -3.1552e-01,  5.3214e-01]],\n",
       "\n",
       "        [[-8.7925e-01, -1.1344e-03, -7.9653e-01,  ...,  1.2170e+00,\n",
       "          -5.8409e-02,  4.8703e-01],\n",
       "         [-3.7978e-01,  5.6242e-02, -9.7089e-01,  ...,  1.4455e+00,\n",
       "          -7.0644e-01,  6.7805e-01],\n",
       "         [-7.8774e-01, -3.1136e-01, -9.4371e-01,  ...,  1.5208e+00,\n",
       "          -1.7221e-01,  6.7768e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-5.8559e-01, -5.2885e-01, -7.4106e-01,  ...,  1.3147e+00,\n",
       "           3.4247e-01,  3.6404e-01],\n",
       "         [-5.5859e-01, -3.7559e-01, -4.6558e-01,  ...,  1.2767e+00,\n",
       "           1.7066e-02,  8.5268e-01],\n",
       "         [-7.9392e-01, -5.8722e-01, -7.1120e-01,  ...,  1.5255e+00,\n",
       "          -5.6226e-01,  4.9165e-01]],\n",
       "\n",
       "        [[-5.7046e-01, -3.3617e-01, -4.4149e-01,  ...,  7.6864e-01,\n",
       "          -3.8521e-01,  3.1885e-01],\n",
       "         [-6.8891e-01,  4.6213e-02, -1.6796e-01,  ...,  9.5890e-01,\n",
       "          -7.8075e-01,  5.0873e-01],\n",
       "         [-4.6586e-01, -3.0355e-02, -4.1976e-01,  ...,  1.3515e+00,\n",
       "          -6.0890e-01,  9.0905e-01]],\n",
       "\n",
       "        [[-4.3407e-01,  5.5416e-01, -3.2760e-01,  ...,  1.3578e+00,\n",
       "          -4.8196e-01,  5.9755e-01],\n",
       "         [-8.0017e-01, -2.8441e-01, -7.5441e-01,  ...,  1.5607e+00,\n",
       "          -3.1740e-01,  1.2444e-01],\n",
       "         [-6.1134e-01, -1.3689e-01, -7.2323e-01,  ...,  1.2541e+00,\n",
       "          -2.6211e-01,  6.2384e-02]]], device='cuda:0',\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = torch.randint(0, 1, (10,3)).to(\"cuda:0\")\n",
    "trg = torch.randint(0, 1, (10,3)).to(\"cuda:0\")\n",
    "model(src,trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "last",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
